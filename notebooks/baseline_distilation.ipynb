{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdbc88c",
   "metadata": {},
   "source": [
    "## Masked Distilation\n",
    "\n",
    "\n",
    "### Baseline:\n",
    "* Bool masking of weights trained model\n",
    "* Gradient descent of loss by continious mask\n",
    "* Clipping masks to bool value\n",
    "\n",
    "### Ours:\n",
    "* Bool masking of weights trained model\n",
    "* Frank Wolfe of loss by continious mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84553ee",
   "metadata": {},
   "source": [
    "## Baseline implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0bb691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added repo root to sys.path: /Users/igoreshka/Desktop/CFW-in-ML\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "print(f\"Added repo root to sys.path: {repo_root}\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from src.model import MLP\n",
    "from src.trainer import Trainer\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699fa4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS, CUDA, or CPU\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342cb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 17:35:03,080 - INFO - Epoch 1: Train Loss = 0.2286, Test Loss = 0.1217, Accuracy = 96.27%\n",
      "2025-05-24 17:35:07,548 - INFO - Epoch 2: Train Loss = 0.0867, Test Loss = 0.0930, Accuracy = 97.16%\n",
      "2025-05-24 17:35:11,922 - INFO - Epoch 3: Train Loss = 0.0583, Test Loss = 0.0731, Accuracy = 97.74%\n",
      "2025-05-24 17:35:16,296 - INFO - Epoch 4: Train Loss = 0.0411, Test Loss = 0.0829, Accuracy = 97.58%\n",
      "2025-05-24 17:35:20,672 - INFO - Epoch 5: Train Loss = 0.0310, Test Loss = 0.0800, Accuracy = 97.77%\n",
      "2025-05-24 17:35:25,061 - INFO - Epoch 6: Train Loss = 0.0283, Test Loss = 0.0779, Accuracy = 97.99%\n",
      "2025-05-24 17:35:29,434 - INFO - Epoch 7: Train Loss = 0.0229, Test Loss = 0.0869, Accuracy = 97.86%\n",
      "2025-05-24 17:35:33,756 - INFO - Epoch 8: Train Loss = 0.0205, Test Loss = 0.0955, Accuracy = 97.81%\n",
      "2025-05-24 17:35:38,099 - INFO - Epoch 9: Train Loss = 0.0171, Test Loss = 0.0760, Accuracy = 98.23%\n",
      "2025-05-24 17:35:42,446 - INFO - Epoch 10: Train Loss = 0.0163, Test Loss = 0.0994, Accuracy = 97.80%\n",
      "2025-05-24 17:35:42,473 - INFO - Model and logs saved to checkpoints/ckpt_0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Инициализация и обучение модели\n",
    "model = MLP().to(device=DEVICE)\n",
    "trainer = Trainer(dataset_name='MNIST', batch_size=64, model=model, checkpoint_path='checkpoints/ckpt_0', device=DEVICE)\n",
    "trainer.train(n_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0aae396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MaskedLinear(nn.Module):\n",
    "    def __init__(self, linear_layer):\n",
    "        super().__init__()\n",
    "        self.linear = linear_layer\n",
    "        self.mask = nn.Parameter(torch.ones_like(linear_layer.weight))\n",
    "\n",
    "    def forward(self, x):\n",
    "        masked_weight = self.linear.weight * self.mask\n",
    "        return nn.functional.linear(x, masked_weight, self.linear.bias)\n",
    "\n",
    "\n",
    "def apply_masked_linear(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            setattr(model, name, MaskedLinear(module))\n",
    "        else:\n",
    "            apply_masked_linear(module)  # рекурсивно проходим по слоям\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e3e61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Маскирование весов\n",
    "ckpt_path = 'checkpoints/ckpt_0/model.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt)  # <- вот здесь без ['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a2a0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Загружаем модель и freeze'им веса\n",
    "masked_model = copy.deepcopy(model)\n",
    "for param in masked_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Оборачиваем линейные слои\n",
    "apply_masked_linear(masked_model)\n",
    "\n",
    "# 3. Расмаскируем параметры масок\n",
    "mask_params = [module.mask for module in masked_model.modules() if isinstance(module, MaskedLinear)]\n",
    "for p in mask_params:\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam(mask_params, lr=1e-1)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. Обучение масок\n",
    "n_mask_epochs = 1\n",
    "for epoch in range(n_mask_epochs):\n",
    "    for x, y in trainer.train_loader:\n",
    "        x, y = x.to(trainer.device), y.to(trainer.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = masked_model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        loss.backward()  # ← градиенты посчитаны тут\n",
    "\n",
    "        # # теперь можно посмотреть на градиенты масок\n",
    "        # for module in masked_model.modules():\n",
    "        #     if isinstance(module, MaskedLinear):\n",
    "        #         print(module.mask.grad)  # ← теперь не None\n",
    "\n",
    "        optimizer.step()\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7b34ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0000,  1.9594,  1.4129,  ...,  0.4427,  2.3374,  2.1956],\n",
      "        [ 1.0000,  2.2058,  0.4408,  ...,  1.5718,  1.1755,  1.8411],\n",
      "        [ 1.0000, -1.1590,  1.3135,  ...,  0.9250,  0.4462,  1.1584],\n",
      "        ...,\n",
      "        [ 1.0000,  2.6824,  1.3716,  ...,  0.1664,  3.6657,  0.7383],\n",
      "        [ 1.0000,  1.1696,  2.7084,  ...,  1.0120,  2.8961,  1.4096],\n",
      "        [ 1.0000,  2.1034,  1.0000,  ..., -1.2630,  2.2218,  1.0000]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.0073, -0.1485, -1.7482,  ...,  2.1074,  3.0330,  4.3077],\n",
      "        [ 1.0672,  1.8483,  1.9075,  ...,  2.7925,  3.9435,  2.1373],\n",
      "        [ 2.3592,  0.1757,  0.4319,  ..., -1.4476, -0.2576,  1.4446],\n",
      "        ...,\n",
      "        [ 3.1654,  0.7709,  1.1604,  ...,  1.1860,  2.2882,  0.7549],\n",
      "        [ 1.3264,  0.5296, -1.3311,  ..., -2.1562,  0.8941,  4.6170],\n",
      "        [ 2.1272,  1.5561, -0.5343,  ...,  1.9383,  1.3321, -1.1860]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for module in masked_model.modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            print(module.mask)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcbedec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_ratio = 0.10  # 10%\n",
    "\n",
    "with torch.no_grad():\n",
    "    for module in masked_model.modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            mean_per_neuron = module.mask.abs().mean(dim=1)  # shape: [output_dim]\n",
    "            n_prune = int(prune_ratio * mean_per_neuron.numel())\n",
    "            if n_prune == 0:\n",
    "                continue  # если слишком мало нейронов — ничего не делаем\n",
    "            prune_indices = torch.topk(mean_per_neuron, k=n_prune, largest=False).indices\n",
    "            keep_mask = torch.ones_like(mean_per_neuron)\n",
    "            keep_mask[prune_indices] = 0.0\n",
    "            keep_mask = keep_mask.view(-1, 1)  # для broadcast по входам\n",
    "            module.mask.data *= keep_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a29258c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model: Test Loss = 0.0994, Accuracy = 97.80%\n",
      "Masked model: Test Loss = 0.2265, Accuracy = 94.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.22649068035781383, 94.52)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(model, description=\"Original model\")\n",
    "trainer.evaluate_model(masked_model, description=\"Masked model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06512255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pruned_mlp(masked_model, input_dim=28*28, output_dim=10):\n",
    "    # Сначала получаем список слоёв MaskedLinear из masked_model (в правильном порядке)\n",
    "    masked_linears = [m for m in masked_model.modules() if isinstance(m, MaskedLinear)]\n",
    "    \n",
    "    # Запишем размеры слоёв по маске (сколько нейронов осталось)\n",
    "    layer_output_masks = []\n",
    "    for layer in masked_linears:\n",
    "        # Маска shape: [out_dim, in_dim]\n",
    "        mask = layer.mask.abs()\n",
    "        # Средняя маска по входам нейрона\n",
    "        mean_per_neuron = mask.mean(dim=1)\n",
    "        # Нейроны, которые НЕ занулены полностью (mean > 0)\n",
    "        keep_neurons = (mean_per_neuron > 0).cpu()\n",
    "        layer_output_masks.append(keep_neurons)\n",
    "    \n",
    "    # Размерности скрытых слоёв (число оставшихся нейронов в каждом слое)\n",
    "    hidden_dims = [mask.sum().item() for mask in layer_output_masks[:-1]]  # все кроме последнего слоя\n",
    "    # Последний слой должен иметь output_dim нейронов (обычно 10)\n",
    "    # Но, если последний слой тоже прунинговали — оставим сколько есть\n",
    "    last_layer_out_dim = layer_output_masks[-1].sum().item()\n",
    "    if last_layer_out_dim != output_dim:\n",
    "        print(f\"Warning: output layer pruned to {last_layer_out_dim} neurons instead of {output_dim}\")\n",
    "        output_dim = last_layer_out_dim\n",
    "    \n",
    "    # Создаём новую модель MLP с нужными hidden_dims\n",
    "    new_mlp = MLP(input_dim=input_dim, output_dim=output_dim, hidden_dims=hidden_dims)\n",
    "    \n",
    "    # Копируем веса из masked_model в new_mlp с учётом масок\n",
    "    prev_keep_mask = torch.ones(input_dim, dtype=torch.bool)  # входной слой — все входы\n",
    "    \n",
    "    for i, (old_layer, new_layer, keep_mask) in enumerate(zip(masked_linears, new_mlp.model, layer_output_masks)):\n",
    "        # keep_mask — булев mask для выходных нейронов слоя (out_dim)\n",
    "        keep_mask = keep_mask.to(old_layer.mask.device)\n",
    "        \n",
    "        # old weights: [out_dim, in_dim]\n",
    "        w = old_layer.linear.weight.data\n",
    "        b = old_layer.linear.bias.data if old_layer.linear.bias is not None else None\n",
    "        \n",
    "        # Обрезаем вес по входам (столбцам), оставляем только prev_keep_mask\n",
    "        w = w[:, prev_keep_mask]\n",
    "        \n",
    "        # Обрезаем вес по выходам (строкам) — оставляем keep_mask\n",
    "        w = w[keep_mask, :]\n",
    "        \n",
    "        if b is not None:\n",
    "            b = b[keep_mask]\n",
    "        \n",
    "        # Копируем в new_layer (nn.Linear)\n",
    "        new_layer.weight.data = w.clone()\n",
    "        if b is not None:\n",
    "            new_layer.bias.data = b.clone()\n",
    "        else:\n",
    "            new_layer.bias = None\n",
    "        \n",
    "        # Теперь входной маск для следующего слоя — это keep_mask\n",
    "        prev_keep_mask = keep_mask\n",
    "    \n",
    "    return new_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579c53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_neurons(masked_linear):\n",
    "    # Предполагается, что masked_linear.mask shape == weight.shape\n",
    "    # Для нейронов (выходов) — это строки\n",
    "    row_mask = masked_linear.mask.abs().sum(dim=1) > 0\n",
    "    return row_mask  # bool-тензор длины out_features\n",
    "def prune_linear_layer(old_layer, active_out_indices, active_in_indices):\n",
    "    new_layer = nn.Linear(\n",
    "        in_features=len(active_in_indices),\n",
    "        out_features=len(active_out_indices),\n",
    "        bias=old_layer.bias is not None,\n",
    "    )\n",
    "\n",
    "    # Скопируем веса и байасы\n",
    "    with torch.no_grad():\n",
    "        new_weight = old_layer.weight[active_out_indices][:, active_in_indices]\n",
    "        new_layer.weight.copy_(new_weight)\n",
    "\n",
    "        if old_layer.bias is not None:\n",
    "            new_layer.bias.copy_(old_layer.bias[active_out_indices])\n",
    "    \n",
    "    return new_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd7f5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_neurons(module, threshold=0):\n",
    "    # Возвращает булев вектор, какие выходные нейроны активны\n",
    "    mask = module.mask.abs()\n",
    "    mean_mask = mask.mean(dim=1)  # среднее по входам\n",
    "    return mean_mask > threshold\n",
    "\n",
    "def prune_linear_layer(module, out_indices, in_indices):\n",
    "    # Создаёт новый nn.Linear с весами обрезанными по индексам out_indices (выходы) и in_indices (входы)\n",
    "    new_layer = nn.Linear(len(in_indices), len(out_indices), bias=module.linear.bias is not None)\n",
    "    new_layer.weight.data = module.linear.weight.data[out_indices][:, in_indices].clone()\n",
    "    if module.linear.bias is not None:\n",
    "        new_layer.bias.data = module.linear.bias.data[out_indices].clone()\n",
    "    return new_layer\n",
    "\n",
    "def convert_masked_to_pruned_model(masked_model, input_dim=28*28, output_dim=10):\n",
    "    pruned_layers = []\n",
    "    prev_active_indices = None\n",
    "    modules = [m for m in masked_model.modules() if isinstance(m, MaskedLinear)]\n",
    "    \n",
    "    for i, module in enumerate(modules):\n",
    "        if i == len(modules) - 1:\n",
    "            # Для последнего слоя не пруним выходные нейроны - оставляем все\n",
    "            out_indices = torch.arange(module.linear.weight.shape[0])\n",
    "        else:\n",
    "            active_neurons = get_active_neurons(module)\n",
    "            out_indices = torch.where(active_neurons)[0]\n",
    "\n",
    "        in_indices = (\n",
    "            torch.arange(module.linear.weight.shape[1])\n",
    "            if prev_active_indices is None\n",
    "            else prev_active_indices\n",
    "        )\n",
    "        \n",
    "        pruned_layer = prune_linear_layer(module, out_indices, in_indices)\n",
    "        pruned_layers.append(pruned_layer)\n",
    "        prev_active_indices = out_indices\n",
    "    \n",
    "    # hidden_dims для новой модели\n",
    "    hidden_dims = [layer.out_features for layer in pruned_layers[:-1]]\n",
    "    pruned_output_dim = pruned_layers[-1].out_features\n",
    "    \n",
    "    # Создаём новую MLP с нужными размерами слоёв\n",
    "    pruned_model = MLP(input_dim=input_dim, output_dim=pruned_output_dim, hidden_dims=hidden_dims)\n",
    "\n",
    "    # Копируем веса\n",
    "    pruned_model_layers = [module for module in pruned_model.model if isinstance(module, nn.Linear)]\n",
    "    for new_layer, old_layer in zip(pruned_model_layers, pruned_layers):\n",
    "        new_layer.weight.data = old_layer.weight.data.clone()\n",
    "        if old_layer.bias is not None:\n",
    "            new_layer.bias.data = old_layer.bias.data.clone()\n",
    "        else:\n",
    "            new_layer.bias = None\n",
    "\n",
    "    return pruned_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c03342a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = convert_masked_to_pruned_model(masked_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b93be095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model: Test Loss = 0.0994, Accuracy = 97.80%\n",
      "Masked model: Test Loss = 0.2265, Accuracy = 94.52%\n",
      "Pruned model: Test Loss = 0.0990, Accuracy = 97.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.09896772104129486, 97.7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate_model(model, description=\"Original model\")\n",
    "trainer.evaluate_model(masked_model, description=\"Masked model\")\n",
    "trainer.evaluate_model(pruned_model, description=\"Pruned model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "527ab45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model:\n",
      "Total parameters in model: 669706\n",
      "\n",
      "Parameters by Linear layer:\n",
      "Layer 2 (Linear): weights = 401408, bias = 512, total = 401920\n",
      "Layer 4 (Linear): weights = 262144, bias = 512, total = 262656\n",
      "Layer 6 (Linear): weights = 5120, bias = 10, total = 5130\n",
      "\n",
      "Masked model:\n",
      "Total parameters in model: 1338378\n",
      "\n",
      "Parameters by Linear layer:\n",
      "Layer 2 (MaskedLinear): weights = 401408, bias = 512, mask = 401408, total = 803328\n",
      "Layer 3 (Linear): weights = 401408, bias = 512, total = 401920\n",
      "Layer 5 (MaskedLinear): weights = 262144, bias = 512, mask = 262144, total = 524800\n",
      "Layer 6 (Linear): weights = 262144, bias = 512, total = 262656\n",
      "Layer 8 (MaskedLinear): weights = 5120, bias = 10, mask = 5120, total = 10250\n",
      "Layer 9 (Linear): weights = 5120, bias = 10, total = 5130\n",
      "\n",
      "Pruned model:\n",
      "Total parameters in model: 579487\n",
      "\n",
      "Parameters by Linear layer:\n",
      "Layer 2 (Linear): weights = 361424, bias = 461, total = 361885\n",
      "Layer 4 (Linear): weights = 212521, bias = 461, total = 212982\n",
      "Layer 6 (Linear): weights = 4610, bias = 10, total = 4620\n"
     ]
    }
   ],
   "source": [
    "def count_all_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters in model: {total_params}\")\n",
    "\n",
    "    print(\"\\nParameters by Linear layer:\")\n",
    "    for i, module in enumerate(model.modules()):\n",
    "        if isinstance(module, nn.Linear) or (hasattr(module, 'linear') and isinstance(module.linear, nn.Linear)):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                w = module.weight.numel()\n",
    "                b = module.bias.numel() if module.bias is not None else 0\n",
    "                print(f\"Layer {i} (Linear): weights = {w}, bias = {b}, total = {w+b}\")\n",
    "            else:  # Например MaskedLinear\n",
    "                w = module.linear.weight.numel()\n",
    "                b = module.linear.bias.numel() if module.linear.bias is not None else 0\n",
    "                m = module.mask.numel()\n",
    "                print(f\"Layer {i} (MaskedLinear): weights = {w}, bias = {b}, mask = {m}, total = {w+b+m}\")\n",
    "\n",
    "# Пример использования:\n",
    "print(\"Original model:\")\n",
    "count_all_params(model)\n",
    "\n",
    "print(\"\\nMasked model:\")\n",
    "count_all_params(masked_model)\n",
    "\n",
    "print(\"\\nPruned model:\")\n",
    "count_all_params(pruned_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
